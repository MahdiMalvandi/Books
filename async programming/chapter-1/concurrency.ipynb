{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Concurrency and Parallelism\n",
    " Take, for instance, a baker baking two different cakes. To bake these\n",
    "cakes, we need to preheat our oven. Preheating can take tens of minutes depending on the oven and the baking temperature, but we don’t need to wait for our oven to\n",
    "preheat before starting other tasks, such as mixing the flour and sugar together with\n",
    "eggs. We can do other work until the oven beeps, letting us know it is preheated.\n",
    " We also don’t need to limit ourselves from starting work on the second cake before\n",
    "finishing the first. We can start one cake batter, put it in a stand mixer, and start pre￾paring the second batter while the first batter finishes mixing. In this model, we’re\n",
    "switching between different tasks concurrently. This switching between tasks (doing\n",
    "something else while the oven heats, switching between two different cakes) is concurrent behavior\n",
    "<img src=\"PdfIamage.png\" height=\"500\">\n",
    "With concurrency, we have multiple tasks happening at the same time, but only\n",
    "one we’re actively doing at a given point in time. With parallelism, we have multiple tasks\n",
    "happening and are actively doing more than one simultaneously.\n",
    "<img src=\"PdfImage.png\" height=\"500\">\n",
    " With concurrency, we switch between running two applications. With\n",
    "parallelism, we actively run two applications simultaneously.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PREEMPTIVE MULTITASKING\n",
    "In this model, we let the operating system decide how to switch between which work is\n",
    "currently being executed via a process called time slicing. When the operating system\n",
    "switches between work, we call it preempting.\n",
    " How this mechanism works under the hood is up to the operating system itself. It is\n",
    "primarily achieved through using either multiple threads or multiple processes.\n",
    "## COOPERATIVE MULTITASKING\n",
    "In this model, instead of relying on the operating system to decide when to switch\n",
    "between which work is currently being executed, we explicitly code points in our\n",
    "application where we can let other tasks run. The tasks in our application operate in a\n",
    "model where they cooperate, explicitly saying, “I’m pausing my task for a while; go ahead\n",
    "and run other tasks.“ asyncio uses cooperative multitasking to achieve concurrency\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Process\n",
    "A process is an application run that has a memory space that other applications cannot\n",
    "access. An example of creating a Python process would be running a simple “hello\n",
    "world” application or typing python at the command line to start up the REPL (read\n",
    "eval print loop). Multiple processes can run on a single machine. If we are on a machine that has a\n",
    "CPU with multiple cores, we can execute multiple processes at the same time. If we\n",
    "are on a CPU with only one core, we can still have multiple applications running\n",
    "simultaneously, through time slicing.\n",
    "\n",
    "# Thread\n",
    "Threads can be thought of as lighter-weight processes. In addition, they are the small￾est construct that can be managed by an operating system. They do not have their own\n",
    "memory as does a process; instead, they share the memory of the process that created\n",
    "them. Threads are associated with the process that created them. A process will always\n",
    "have at least one thread associated with it, usually known as the main thread. A process\n",
    "can also create other threads, which are more commonly known as worker or back￾ground threads.When we run a normal Python application, we create a process as well as a main\n",
    "thread that will be responsible for running our Python application.\n",
    "<img src=\"process-vs-thread3.png\" height=\"500\">\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Understanding the global interpreter lock\n",
    "The global interpreter lock, abbreviated GIL and pronounced gill, is a controversial\n",
    "topic in the Python community. Briefly, the GIL prevents one Python process from\n",
    "executing more than one Python bytecode instruction at any given time. This means\n",
    "that even if we have multiple threads on a machine with multiple cores, a Python\n",
    "process can have only one thread running Python code at a time. In a world where we\n",
    "have CPUs with multiple cores, this can pose a significant challenge for Python devel￾opers looking to take advantage of multithreading to improve the performance of\n",
    "their application.\n",
    "\n",
    "<span style=\"font-weight:bold;\">NOTE</span> Multiprocessing can run multiple bytecode instructions concurrently\n",
    "because each Python process has its own GIL\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So why does the GIL exist? The answer lies in how memory is managed in CPython. In\n",
    "CPython, memory is managed primarily by a process known as reference counting.\n",
    "<br>\n",
    "\n",
    "<span style=\"font-weight:bold;\">What is CPython?</span>\n",
    "CPython is the reference implementation of Python. By reference implementation we\n",
    "mean it is the standard implementation of the language and is used as the reference\n",
    "for proper behavior of the language. There are other implementations of Python such\n",
    "as Jython, which is designed to run on the Java Virtual Machine, and IronPython,\n",
    "which is designed for the .NET framework.\n",
    "\n",
    "\n",
    "The conflict with threads arises in that the implementation in CPython is not thread\n",
    "safe. When we say CPython is not thread safe, we mean that if two or more threads mod￾ify a shared variable, that variable may end in an unexpected state. This unexpected\n",
    "state depends on the order in which the threads access the variable, commonly known\n",
    "as a race condition.Race conditions can arise when two threads need to reference a\n",
    "Python object at the same time.\n",
    " As shown in figure 1.6, if two threads increment the reference count at one time,\n",
    "we could face a situation where one thread causes the reference count to be zero\n",
    "when the object is still in use by the other thread.\n",
    "<img src=\"GIL_benefit.png\" height=\"500\">\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A race condition where two threads try to increment a reference count simultaneously. Instead of an expected count of two, we get one."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fib(40) is 63245986\n",
      "fib(41) is 102334155\n",
      "Completed in 38.2830 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def print_fib(number: int) -> None:\n",
    "    def fib(n: int) -> int:\n",
    "        if n == 1:\n",
    "            return 0\n",
    "        elif n == 2:\n",
    "            return 1\n",
    "        else:\n",
    "            return fib(n - 1) + fib(n - 2)\n",
    "    print(f'fib({number}) is {fib(number)}')\n",
    "def fibs_no_threading():\n",
    " print_fib(40)\n",
    " print_fib(41)\n",
    "start = time.time()\n",
    "fibs_no_threading()\n",
    "end = time.time()\n",
    "print(f'Completed in {end - start:.4f} seconds.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-28T11:22:12.723559300Z",
     "start_time": "2024-07-28T11:21:34.437613800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threads took 0.0010 seconds.\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "def print_fib(number: int) -> None:\n",
    "    def fib(n: int) -> int:\n",
    "        if n == 1:\n",
    "            return 0\n",
    "        elif n == 2:\n",
    "            return 1\n",
    "        else:\n",
    "            return fib(n - 1) + fib(n - 2)\n",
    "def fibs_with_threads():\n",
    "    fortieth_thread = threading.Thread(target=print_fib, args=(40,))\n",
    "    forty_first_thread = threading.Thread(target=print_fib, args=(41,))\n",
    "    fortieth_thread.start()\n",
    "    forty_first_thread.start()\n",
    "    fortieth_thread.join()\n",
    "    forty_first_thread.join()\n",
    "start_threads = time.time()\n",
    "fibs_with_threads()\n",
    "end_threads = time.time()\n",
    "print(f'Threads took {end_threads - start_threads:.4f} seconds.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-28T11:22:12.731196300Z",
     "start_time": "2024-07-28T11:22:12.726562700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Our threaded version took almost the same amount of time. In fact, it was even a little\n",
    "slower! This is almost entirely due to the GIL and the overhead of creating and manag￾ing threads. While it is true the threads run concurrently, only one of them is allowed to\n",
    "run Python code at a time due to the lock. This leaves the other thread in a waiting state\n",
    "until the first one completes, which completely negates the value of multiple threads.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " The global interpreter lock is released when I/O operations happen. This lets us\n",
    "employ threads to do concurrent work when it comes to I/O, but not for CPU-bound\n",
    "Python code itself (there are some notable exceptions that release the GIL for CPU￾bound work in certain circumstances, and we’ll look at these in a later chapter). To\n",
    "illustrate this, let’s use an example of reading the status code of a web page.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# asyncio and the GIL\n",
    "asyncio exploits the fact that I/O operations release the GIL to give us concurrency,\n",
    "even with only one thread. When we utilize asyncio we create objects called coroutines.\n",
    "A coroutine can be thought of as executing a lightweight thread. Much like we can\n",
    "have multiple threads running at the same time, each with their own concurrent I/O\n",
    "operation, we can have many coroutines running alongside one another. While we are\n",
    "waiting for our I/O-bound coroutines to finish, we can still execute other Python\n",
    "code, thus, giving us concurrency. It is important to note that asyncio does not circum￾vent the GIL, and we are still subject to it. If we have a CPU-bound task, we still need\n",
    "to use multiple processes to execute it concurrently (which can be done with asyncio\n",
    "itself); otherwise, we will cause performance issues in our application. Now that we\n",
    "know it is possible to achieve concurrency for I/O with only a single thread, let’s dive\n",
    "into the specifics of how this works with non-blocking sockets."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Socket\n",
    "<img src=\"socket-thread.png\" height=\"500\">\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## How an event loop works\n",
    "An event loop is at the heart of every asyncio application. Event loops are a fairly com-mon design pattern in many systems and have existed for quite some time.Event loops run asynchronous tasks and callbacks, perform network IO operations, and run subprocesses.\n",
    "In asyncio, the event loop keeps a queue of tasks instead of messages.  Tasks are wrap￾pers around a coroutine. A coroutine can pause execution when it hits an I/O-bound\n",
    "operation and will let the event loop run other tasks that are not waiting for I/O oper￾ations to complete.When we create an event loop, we create an empty queue of tasks. We can then add\n",
    "tasks into the queue to be run. Each iteration of the event loop checks for tasks that need\n",
    "to be run and will run them one at a time until a task hits an I/O operation. At that time\n",
    "the task will be “paused,” and we instruct our operating system to watch any sockets for\n",
    "I/O to complete.\n",
    "On every iteration of the\n",
    "event loop, we’ll check to see if any of our I/O has completed; if it has, we’ll “wake up”\n",
    "any tasks that were paused and let them finish running. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
